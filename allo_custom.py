import numpy as np
import pandas as pd
import streamlit as st
from scipy.optimize import minimize

st.set_page_config(
    page_title="[ê¸€ë¡œë²Œìì‚°ë°°ë¶„ì „ëµìœ„ì›íšŒ] Allocation",
    layout="wide",
)

# ì‚¬ì´ë“œë°” í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì • CSS
st.markdown("""
    <style>
        /* ì‚¬ì´ë“œë°” ì „ì²´ í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì • */
        [data-testid="stSidebar"] {
            font-size: 14px !important;
        }

        /* ì‚¬ì´ë“œë°” ì œëª© */
        [data-testid="stSidebar"] h1,
        [data-testid="stSidebar"] h2,
        [data-testid="stSidebar"] h3 {
            font-size: 16px !important;
        }

        /* ì‚¬ì´ë“œë°” ë³¸ë¬¸ í…ìŠ¤íŠ¸ */
        [data-testid="stSidebar"] p,
        [data-testid="stSidebar"] div,
        [data-testid="stSidebar"] span {
            font-size: 14px !important;
        }

        /* ì‚¬ì´ë“œë°” ì…ë ¥ í•„ë“œ */
        [data-testid="stSidebar"] input,
        [data-testid="stSidebar"] select,
        [data-testid="stSidebar"] textarea {
            font-size: 14px !important;
        }

        /* ì‚¬ì´ë“œë°” ë¼ë””ì˜¤ ë²„íŠ¼, ì²´í¬ë°•ìŠ¤ */
        [data-testid="stSidebar"] label {
            font-size: 14px !important;
        }

        /* ì‚¬ì´ë“œë°” ë²„íŠ¼ */
        [data-testid="stSidebar"] button {
            font-size: 14px !important;
        }

        /* ì‚¬ì´ë“œë°” ë©”íŠ¸ë¦­ */
        [data-testid="stSidebar"] [data-testid="stMetricValue"] {
            font-size: 15px !important;
        }

        [data-testid="stSidebar"] [data-testid="stMetricLabel"] {
            font-size: 13px !important;
        }
    </style>
""", unsafe_allow_html=True)


def normalize_percentage(value):
    """Convert Excel-style percentage to decimal."""
    if pd.isna(value):
        return np.nan

    if isinstance(value, str):
        cleaned = value.replace("%", "").replace(",", "").strip()
        if cleaned == "":
            return np.nan
        try:
            value = float(cleaned)
        except ValueError:
            return np.nan

    try:
        value = float(value)
    except (TypeError, ValueError):
        return np.nan

    return value / 100 if value > 1.5 else value


def load_excel(uploaded_file):
    """Read Excel file."""
    price_df = pd.read_excel(uploaded_file, sheet_name="ê¸°ì¤€ê°€")
    current_df = pd.read_excel(uploaded_file, sheet_name="Current")
    asset_minmax_df = pd.read_excel(uploaded_file, sheet_name="Asset_MinMax")
    group_df = pd.read_excel(uploaded_file, sheet_name="Gr_MinMax")

    # BM ì‹œíŠ¸ëŠ” ì„ íƒì‚¬í•­
    bm_df = None
    try:
        bm_df = pd.read_excel(uploaded_file, sheet_name="BM")
    except:
        pass

    return price_df, current_df, asset_minmax_df, group_df, bm_df


def prepare_current_df(df):
    """Clean Current sheet."""
    clean_df = df.copy()
    for col in ["CURRENT", "MIN", "MAX", "EXPECTED_R", "YLD"]:
        if col in clean_df.columns:
            if col == "EXPECTED_R":
                # EXPECTED_Rì€ íŠ¹ë³„ ì²˜ë¦¬: 5.0 ë˜ëŠ” 500ì„ "ê¸°ëŒ€ê°’ ì—†ìŒ"ìœ¼ë¡œ ì¸ì‹
                # ì›ë³¸ ê°’ì„ ë¨¼ì € í™•ì¸
                original_values = clean_df[col].copy()
                clean_df[col] = clean_df[col].apply(normalize_percentage)
                # 5.0 ë˜ëŠ” 500ì„ "ê¸°ëŒ€ê°’ ì—†ìŒ"ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ê·¸ëŒ€ë¡œ ìœ ì§€
                mask_5 = np.isclose(original_values, 5.0, atol=0.1) | np.isclose(original_values, 500.0, atol=1.0)
                # normalize_percentage ì ìš© í›„ 0.05ê°€ ëœ ê²½ìš°ë¥¼ 5.0ìœ¼ë¡œ ë³µì›
                mask_normalized = np.isclose(clean_df[col], 0.05, atol=0.01) & mask_5
                clean_df.loc[mask_normalized, col] = 5.0
            else:
                clean_df[col] = clean_df[col].apply(normalize_percentage)
    return clean_df


def prepare_group_df(df, gd_option="GD"):
    """Clean group constraints."""
    group_df = df.copy()
    # GD ì˜µì…˜ì— ë”°ë¼ ì²˜ë¦¬í•  ì»¬ëŸ¼ ê²°ì •
    if gd_option == "GD":
        cols_to_normalize = ["Min_GD", "Max_GD"]
    else:  # GD+
        cols_to_normalize = ["Min_GDp", "Max_GDp"]
    
    for col in cols_to_normalize:
        if col in group_df.columns:
            group_df[col] = group_df[col].apply(normalize_percentage)
    return group_df


def merge_asset_data(current_df, asset_minmax_df, group_df, gd_option):
    """Merge Current, Asset_MinMax, and Gr_MinMax data based on GD option."""
    # GD ì˜µì…˜ì— ë”°ë¼ ì»¬ëŸ¼ëª… ê²°ì •
    if gd_option == "GD":
        asset_min_col = "Min_GD"
        asset_max_col = "Max_GD"
        group_min_col = "Min_GD"
        group_max_col = "Max_GD"
    else:  # GD+
        asset_min_col = "Min_GDp"
        asset_max_col = "Max_GDp"
        group_min_col = "Min_GDp"
        group_max_col = "Max_GDp"
    
    # Currentì™€ Asset_MinMax ë³‘í•© (CODE, NAMEì„ keyë¡œ)
    # Current ì‹œíŠ¸ì— ì´ë¯¸ GROUPì´ ìˆìœ¼ë¯€ë¡œ Min_GD/Max_GD ë˜ëŠ” Min_GDp/Max_GDpë§Œ ê°€ì ¸ì˜´
    merged_df = current_df.merge(
        asset_minmax_df[["CODE", "NAME", asset_min_col, asset_max_col]],
        on=["CODE", "NAME"],
        how="left"
    )
    
    # Min_GD/Max_GD ë˜ëŠ” Min_GDp/Max_GDpë¥¼ Min, Maxë¡œ ì´ë¦„ ë³€ê²½
    merged_df = merged_df.rename(columns={
        asset_min_col: "MIN",
        asset_max_col: "MAX"
    })
    
    # GROUPìœ¼ë¡œ ì •ë ¬
    merged_df = merged_df.sort_values("GROUP").reset_index(drop=True)
    
    # GROUPì„ keyë¡œ Gr_MinMax ë³‘í•©
    group_merge_cols = ["GROUP", group_min_col, group_max_col]
    if all(col in group_df.columns for col in group_merge_cols):
        merged_df = merged_df.merge(
            group_df[group_merge_cols],
            on="GROUP",
            how="left"
        )
        # Gr_MinMax ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½
        merged_df = merged_df.rename(columns={
            group_min_col: "Gr_Min",
            group_max_col: "Gr_Max"
        })
    else:
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì¶”ê°€
        merged_df["Gr_Min"] = np.nan
        merged_df["Gr_Max"] = np.nan
    
    return merged_df


def format_percentage_int(value):
    """Format as integer percentage (no decimals)."""
    if pd.isna(value):
        return ""
    return f"{int(value * 100)}%"


def format_percentage_1dec(value):
    """Format as percentage with 1 decimal."""
    if pd.isna(value):
        return ""
    return f"{value * 100:.1f}%"


def format_percentage_2dec(value):
    """Format as percentage with 2 decimals, or 'X' if value is 5.0."""
    if pd.isna(value):
        return ""
    # 5.0 (500%)ì¸ ê²½ìš° Xë¡œ í‘œì‹œ
    if np.isclose(value, 5.0, atol=0.1):
        return "X"
    return f"{value * 100:.2f}%"


def format_display_df(df, raw_expected_r=None):
    """Format dataframe for display with special formatting."""
    display_df = df.copy()
    
    # CODE ì»¬ëŸ¼ ì œê±°
    if "CODE" in display_df.columns:
        display_df = display_df.drop(columns=["CODE"])
    
    # CURRENTë¥¼ ì†Œìˆ«ì  ì²«ì§¸ìë¦¬ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    if "CURRENT" in display_df.columns:
        display_df["CURRENT"] = display_df["CURRENT"].apply(format_percentage_1dec)
    
    # Min, Max, Gr_Min, Gr_Maxë¥¼ ì •ìˆ˜ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    for col in ["MIN", "MAX", "Gr_Min", "Gr_Max"]:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(format_percentage_int)
    
    # YLDë¥¼ ì†Œìˆ«ì  ë‘˜ì§¸ìë¦¬ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    if "YLD" in display_df.columns:
        display_df["YLD"] = display_df["YLD"].apply(format_percentage_2dec)
    
    # EXPECTED_Rì„ ì†Œìˆ«ì  ë‘˜ì§¸ìë¦¬ í¼ì„¼íŠ¸ë¡œ ë³€í™˜ (5.0ì´ë©´ X)
    if "EXPECTED_R" in display_df.columns:
        display_df["EXPECTED_R"] = display_df["EXPECTED_R"].apply(format_percentage_2dec)
    
    # Gr_Min, Gr_MaxëŠ” ê° GROUPì˜ ì²« í–‰ì—ë§Œ í‘œì‹œ
    if "Gr_Min" in display_df.columns and "GROUP" in display_df.columns:
        if len(display_df) > 0:
            # ì²« í–‰ì€ í•­ìƒ ì²« ê·¸ë£¹ì˜ ì²« í–‰
            display_df["_is_first_in_group"] = False
            display_df.loc[0, "_is_first_in_group"] = True
            # ë‚˜ë¨¸ì§€ í–‰ë“¤ì€ GROUPì´ ë°”ë€ŒëŠ” ì§€ì 
            if len(display_df) > 1:
                display_df.loc[1:, "_is_first_in_group"] = display_df.loc[1:, "GROUP"].values != display_df.loc[:len(display_df)-2, "GROUP"].values
            display_df.loc[~display_df["_is_first_in_group"], "Gr_Min"] = ""
            display_df.loc[~display_df["_is_first_in_group"], "Gr_Max"] = ""
            display_df = display_df.drop(columns=["_is_first_in_group"])
    
    # ì¹¼ëŸ¼ëª… ë³€ê²½
    column_rename = {
        "NAME": "Sleeve",
        "CURRENT": "í˜„ì¬ë¹„ì¤‘",
        "EXPECTED_R": "ê¸°ëŒ€ìˆ˜ìµë¥ "
    }
    display_df = display_df.rename(columns=column_rename)
    
    return display_df


def validate_codes(price_df, codes):
    """Ensure each code exists in price sheet."""
    missing = [code for code in codes if code not in price_df.columns]
    if missing:
        raise ValueError(
            f"ê¸°ì¤€ê°€ ì‹œíŠ¸ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” CODE: {', '.join(missing)}"
        )


def compute_monthly_returns(price_df, codes, months):
    """Build monthly return matrix."""
    data = price_df.copy()
    if "DATE" not in data.columns:
        raise ValueError("ê¸°ì¤€ê°€ ì‹œíŠ¸ì— DATE ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    data["DATE"] = pd.to_datetime(data["DATE"], errors="coerce")
    data = data.sort_values("DATE")
    data = data.set_index("DATE")

    missing_cols = [code for code in codes if code not in data.columns]
    if missing_cols:
        raise ValueError(f"CODEì— í•´ë‹¹í•˜ëŠ” ê¸°ì¤€ê°€ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")

    price_matrix = data[codes].ffill().dropna(how="all")
    monthly_price = price_matrix.resample("M").last()
    monthly_returns = monthly_price.pct_change().dropna(how="all")
    monthly_returns = monthly_returns.tail(months)

    if monthly_returns.empty:
        raise ValueError("ì„ íƒí•œ ì°¸ì¡°ê¸°ê°„ì— í™œìš© ê°€ëŠ¥í•œ ì›”ë³„ ìˆ˜ìµë¥ ì´ ì—†ìŠµë‹ˆë‹¤.")

    return monthly_returns


def compute_bm_returns(bm_df, months):
    """Build BM monthly return series from BM sheet."""
    if bm_df is None:
        return None

    if "DATE" not in bm_df.columns or "TR" not in bm_df.columns:
        return None

    data = bm_df.copy()
    data["DATE"] = pd.to_datetime(data["DATE"], errors="coerce")
    data = data.sort_values("DATE")
    data = data.set_index("DATE")

    # TR ê°’ì´ ëª¨ë‘ 0ì¸ì§€ í™•ì¸
    if data["TR"].fillna(0).abs().sum() < 1e-10:
        return None

    bm_price = data[["TR"]].ffill().dropna(how="all")
    monthly_bm_price = bm_price.resample("M").last()
    monthly_bm_returns = monthly_bm_price.pct_change().dropna(how="all")
    monthly_bm_returns = monthly_bm_returns.tail(months)

    if monthly_bm_returns.empty:
        return None

    return monthly_bm_returns["TR"]


def annualize_series(monthly_series):
    """Convert monthly mean returns to annual."""
    return (1 + monthly_series).pow(12) - 1


def annualize_vol(vol_monthly):
    """Convert monthly vol to annual."""
    return vol_monthly * np.sqrt(12)


def build_expected_returns(method, current_df, hist_returns, monthly_means, cov_monthly, sims, raw_expected_r=None,
                           replacement_method=None):
    codes = current_df["CODE"].tolist()
    excel_values = current_df.set_index("CODE")["EXPECTED_R"]
    hist = hist_returns.reindex(excel_values.index)

    if method == "excel":
        result = excel_values.copy()
        # 5.0 ë˜ëŠ” 500%ëŠ” ê¸°ëŒ€ê°’ì´ ì—†ë‹¤ëŠ” ì˜ë¯¸
        # ì •ê·œí™”ëœ ê°’ì—ì„œ 5.0ì„ ì²´í¬í•˜ê±°ë‚˜, ì›ë³¸ ê°’ì—ì„œ 5.0 ë˜ëŠ” 500ì„ ì²´í¬
        if raw_expected_r is not None:
            raw_aligned = raw_expected_r.reindex(excel_values.index)
            placeholders = result.isna() | np.isclose(result, 5.0, atol=0.1) | (raw_aligned.notna() & (
                        np.isclose(raw_aligned, 5.0, atol=0.1) | np.isclose(raw_aligned, 500.0, atol=1.0)))
        else:
            placeholders = result.isna() | np.isclose(result, 5.0, atol=0.1)
        if placeholders.any():
            # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëŒ€ì²´ ë°©ì‹ìœ¼ë¡œ ê°’ ëŒ€ì²´
            if replacement_method == "monte_carlo":
                # ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëŒ€ì²´
                np.random.seed(42)
                cov = cov_monthly.values + np.eye(len(cov_monthly)) * 1e-8
                try:
                    sims_res = np.random.multivariate_normal(monthly_means.values, cov, size=sims)
                    mc_means = sims_res.mean(axis=0)
                    ann_mc = annualize_series(pd.Series(mc_means, index=monthly_means.index))
                    mc_values = ann_mc.reindex(excel_values.index)
                    result[placeholders] = mc_values[placeholders]
                except np.linalg.LinAlgError:
                    # ê³µë¶„ì‚° í–‰ë ¬ ì˜¤ë¥˜ ì‹œ ê³¼ê±°ìˆ˜ìµë¥ ë¡œ ëŒ€ì²´
                    result[placeholders] = hist[placeholders]
            else:
                # ê³¼ê±°ìˆ˜ìµë¥ ë¡œ ëŒ€ì²´ (default)
                result[placeholders] = hist[placeholders]
    elif method == "historical":
        result = hist.copy()
    else:  # monte_carlo
        np.random.seed(42)
        cov = cov_monthly.values + np.eye(len(cov_monthly)) * 1e-8
        try:
            sims_res = np.random.multivariate_normal(monthly_means.values, cov, size=sims)
            mc_means = sims_res.mean(axis=0)
            ann_mc = annualize_series(pd.Series(mc_means, index=monthly_means.index))
            result = ann_mc.reindex(excel_values.index)
        except np.linalg.LinAlgError:
            result = hist.copy()

    return result.reindex(codes).fillna(0.0)


def build_expected_vols(method, current_df, hist_vols, monthly_means, cov_monthly, sims, raw_expected_v=None,
                        replacement_method=None):
    """Build expected volatilities. Always uses historical volatility since EXPECTED_V is not used."""
    # EXPECTED_VëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ í•­ìƒ ê³¼ê±° ë³€ë™ì„± ì‚¬ìš©
    return hist_vols.copy()


def risk_parity_objective(w, cov):
    portfolio_var = np.dot(w, cov @ w)
    if portfolio_var <= 0:
        return 1e6
    marginal_contrib = cov @ w
    risk_contrib = w * marginal_contrib
    target = portfolio_var / len(w)
    return np.sum((risk_contrib - target) ** 2)


def sortino_ratio(w, returns_matrix, mar, rf):
    port_monthly = returns_matrix @ w
    mar_monthly = (1 + mar) ** (1 / 12) - 1
    downside = np.minimum(port_monthly - mar_monthly, 0)
    downside_dev = np.sqrt(np.mean(downside ** 2)) if np.any(downside) else 1e-6
    ann_return = (1 + port_monthly.mean()) ** 12 - 1
    ann_downside = downside_dev * np.sqrt(12)
    return (ann_return - rf) / ann_downside


def portfolio_stats(w, mu, cov, dur, yld, returns_matrix, mar, rf):
    port_return = np.dot(w, mu)
    port_vol = np.sqrt(np.dot(w, cov @ w))
    sharpe = (port_return - rf) / port_vol if port_vol > 0 else np.nan
    sortino = sortino_ratio(w, returns_matrix, mar, rf)
    duration = np.dot(w, dur)
    portfolio_yield = np.dot(w, yld)
    return {
        "return": port_return,
        "vol": port_vol,
        "sharpe": sharpe,
        "sortino": sortino,
        "duration": duration,
        "yield": portfolio_yield,
    }


def portfolio_vs_bm_stats(w, mu, cov, returns_matrix, bm_returns_monthly):
    """Calculate portfolio vs benchmark comparison statistics."""
    if bm_returns_monthly is None or len(bm_returns_monthly) == 0:
        return None

    # í¬íŠ¸í´ë¦¬ì˜¤ ì›”ë³„ ìˆ˜ìµë¥ 
    port_monthly = returns_matrix @ w

    # ê³µí†µ ê¸°ê°„ ì°¾ê¸°
    common_dates = returns_matrix.index.intersection(bm_returns_monthly.index)
    if len(common_dates) == 0:
        return None

    port_common = port_monthly.loc[common_dates]
    bm_common = bm_returns_monthly.loc[common_dates]

    # ì—°ìœ¨í™”
    port_ann_return = (1 + port_common.mean()) ** 12 - 1
    bm_ann_return = (1 + bm_common.mean()) ** 12 - 1

    # Alpha (ì´ˆê³¼ìˆ˜ìµë¥ )
    alpha = port_ann_return - bm_ann_return

    # Tracking Error (ì—°ìœ¨í™”)
    active_returns = port_common - bm_common
    tracking_error = np.std(active_returns) * np.sqrt(12)

    # Information Ratio
    ir = alpha / tracking_error if tracking_error > 0 else np.nan

    # ìƒê´€ê´€ê³„
    correlation = np.corrcoef(port_common, bm_common)[0, 1] if len(port_common) > 1 else np.nan

    # ë² íƒ€
    if len(port_common) > 1 and np.var(bm_common) > 0:
        beta = np.cov(port_common, bm_common)[0, 1] / np.var(bm_common)
    else:
        beta = np.nan

    return {
        "port_return": port_ann_return,
        "bm_return": bm_ann_return,
        "alpha": alpha,
        "tracking_error": tracking_error,
        "ir": ir,
        "correlation": correlation,
        "beta": beta,
    }


def optimize_portfolio(
        objective,
        mu,
        cov,
        current_w,
        bounds,
        group_map,
        group_limits,
        dur_array,
        yld_array,
        dur_limits,
        yld_limits,
        turnover_limit,
        returns_matrix,
        mar,
        rf,
        bm_returns_monthly=None,
        bm_dur=None,
        bm_yld=None,
        dur_diff_limits=None,
        yld_diff_limits=None,
):
    n_assets = len(current_w)
    eq_weights = np.ones(n_assets) / n_assets

    constraints = [{"type": "eq", "fun": lambda w: np.sum(w) - 1}]
    
    # ë“€ë ˆì´ì…˜ ì ˆëŒ€ê°’ ì œì•½ì¡°ê±´ (BMì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©)
    if dur_limits is not None:
        constraints.append({"type": "ineq", "fun": lambda w: np.dot(w, dur_array) - dur_limits[0]})
        constraints.append({"type": "ineq", "fun": lambda w: dur_limits[1] - np.dot(w, dur_array)})
    
    # YLD ì ˆëŒ€ê°’ ì œì•½ì¡°ê±´ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    # if yld_limits is not None:
    #     constraints.append({"type": "ineq", "fun": lambda w: np.dot(w, yld_array) - yld_limits[0]})
    #     constraints.append({"type": "ineq", "fun": lambda w: yld_limits[1] - np.dot(w, yld_array)})

    # BM ëŒ€ë¹„ ì°¨ì´ ì œì•½ì¡°ê±´
    if bm_dur is not None and dur_diff_limits is not None:
        constraints.append({"type": "ineq", "fun": lambda w: np.dot(w, dur_array) - bm_dur - dur_diff_limits[0]})
        constraints.append({"type": "ineq", "fun": lambda w: dur_diff_limits[1] - (np.dot(w, dur_array) - bm_dur)})

    if bm_yld is not None and yld_diff_limits is not None:
        constraints.append({"type": "ineq", "fun": lambda w: np.dot(w, yld_array) - bm_yld - yld_diff_limits[0]})
        constraints.append({"type": "ineq", "fun": lambda w: yld_diff_limits[1] - (np.dot(w, yld_array) - bm_yld)})

    for group, idx in group_map.items():
        g_min, g_max = group_limits.get(group, (0, 1))
        constraints.append(
            {
                "type": "ineq",
                "fun": lambda w, indices=idx, g=g_min: np.sum(w[indices]) - g,
            }
        )
        constraints.append(
            {
                "type": "ineq",
                "fun": lambda w, indices=idx, g=g_max: g - np.sum(w[indices]),
            }
        )

    if turnover_limit is not None and turnover_limit > 0:
        constraints.append(
            {
                "type": "ineq",
                "fun": lambda w: turnover_limit - np.sum(np.abs(w - current_w)),
            }
        )

    # returns_matrixê°€ DataFrameì¸ì§€ í™•ì¸
    if isinstance(returns_matrix, pd.DataFrame):
        returns_matrix_values = returns_matrix.values
        returns_matrix_index = returns_matrix.index
    else:
        returns_matrix_values = returns_matrix
        returns_matrix_index = None

    def obj_fn(w):
        if objective == "Max Sharpe":
            vol = np.sqrt(np.dot(w, cov @ w))
            ret = np.dot(w, mu)
            if vol == 0:
                return 1e6
            return -((ret - rf) / vol)
        if objective == "Max Sortino":
            return -sortino_ratio(w, returns_matrix_values, mar, rf)
        if objective == "Max Return":
            return -np.dot(w, mu)
        if objective == "Min Risk":
            return np.sqrt(np.dot(w, cov @ w))
        if objective == "Risk Parity":
            return risk_parity_objective(w, cov)
        if objective == "Equal Weight":
            return np.sum((w - eq_weights) ** 2)
        if objective == "Max IR":
            # Information Ratio = Alpha / Tracking Error
            if bm_returns_monthly is None or len(bm_returns_monthly) == 0:
                return 1e6
            if returns_matrix_index is None:
                return 1e6
            port_monthly = pd.Series(returns_matrix_values @ w, index=returns_matrix_index)
            common_dates = returns_matrix_index.intersection(bm_returns_monthly.index)
            if len(common_dates) == 0:
                return 1e6
            port_common = port_monthly.loc[common_dates]
            bm_common = bm_returns_monthly.loc[common_dates]
            active_returns = port_common - bm_common
            tracking_error = np.std(active_returns) * np.sqrt(12)
            port_ann_return = (1 + port_common.mean()) ** 12 - 1
            bm_ann_return = (1 + bm_common.mean()) ** 12 - 1
            alpha = port_ann_return - bm_ann_return
            if tracking_error == 0:
                return 1e6
            ir = alpha / tracking_error
            return -ir  # ìµœëŒ€í™”ë¥¼ ìœ„í•´ ìŒìˆ˜
        return 0.0

    result = minimize(
        obj_fn,
        current_w,
        method="SLSQP",
        bounds=bounds,
        constraints=constraints,
        options={"maxiter": 2000, "ftol": 1e-9, "disp": False},
    )

    if not result.success:
        st.warning(f"{objective} ìµœì í™”ê°€ ìˆ˜ë ´í•˜ì§€ ì•Šì•„ í˜„ì¬ ë¹„ì¤‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        optimized = current_w.copy()
    else:
        optimized = result.x

    optimized = optimized / np.sum(optimized)
    # returns_matrixê°€ DataFrameì¸ì§€ í™•ì¸
    returns_matrix_for_stats = returns_matrix_values if isinstance(returns_matrix, pd.DataFrame) else returns_matrix
    stats = portfolio_stats(optimized, mu, cov, dur_array, yld_array, returns_matrix_for_stats, mar, rf)
    turnover = np.sum(np.abs(optimized - current_w))

    return optimized, stats, turnover


def format_percentage(value):
    return f"{value * 100:.2f}%"


def format_ratio(value):
    if np.isnan(value):
        return "-"
    return f"{value:.2f}"


def main():
    st.title("Asset Allocation Optimizer")
    st.caption("Current / Asset_MinMax / Gr_MinMax / ê¸°ì¤€ê°€ / BM ì‹œíŠ¸ë¥¼ í¬í•¨í•œ ì—‘ì…€ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    # ì˜ˆì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬
    import os
    example_file_path = "images/Streamlit_Upload.xlsx"
    if os.path.exists(example_file_path):
        with open(example_file_path, "rb") as f:
            st.download_button(
                label="ğŸ“¥ ì˜ˆì œ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=f.read(),
                file_name="example.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    uploaded = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì„ íƒ", type=["xlsx", "xls"])
    if uploaded is None:
        st.stop()

    try:
        price_df, current_df_raw, asset_minmax_df, group_df, bm_df = load_excel(uploaded)
    except Exception as exc:
        st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        st.stop()

    # ì‚¬ì´ë“œë°” ìµœìƒë‹¨ì— ì´ë¯¸ì§€ í‘œì‹œ
    try:
        st.sidebar.image("images/miraeasset.png", use_container_width=True)
    except:
        st.sidebar.warning("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # BM ì‚¬ìš© ì—¬ë¶€ ì„ íƒ
    use_bm = st.sidebar.radio(
        "BM ì‚¬ìš© ì—¬ë¶€",
        ("ì‚¬ìš© ì•ˆí•¨", "ì‚¬ìš©"),
        index=0,
    )

    has_bm = (use_bm == "ì‚¬ìš©")

    # GD/GD+ ì„ íƒ
    gd_option = st.sidebar.radio(
        "GD or GD+",
        ("GD", "GD+"),
        index=0,
    )

    # BM ì‚¬ìš© ì‹œ BM ì‹œíŠ¸ ê²€ì¦
    if has_bm:
        if bm_df is None:
            st.error("DATE, TR, DUR, YLD ì¹¼ëŸ¼ì„ ê°€ì§„ BM ì‹œíŠ¸ê°€ ì…ë ¥íŒŒì¼ì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()

        # BM ì‹œíŠ¸ ì¹¼ëŸ¼ ê²€ì¦
        required_cols = ["DATE", "TR", "DUR", "YLD"]
        missing_cols = [col for col in required_cols if col not in bm_df.columns]
        if missing_cols:
            st.error(f"BM ì‹œíŠ¸ì— ë‹¤ìŒ ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
            st.stop()

    # normalize_percentage ì ìš© ì „ ì›ë³¸ ê°’ í™•ì¸ (5.0 ë˜ëŠ” 500% ì²´í¬ìš©)
    raw_expected_r = current_df_raw.set_index("CODE")[
        "EXPECTED_R"] if "EXPECTED_R" in current_df_raw.columns else pd.Series()

    current_df = prepare_current_df(current_df_raw)
    group_df_prepared = prepare_group_df(group_df, gd_option)
    
    # ë°ì´í„° ë³‘í•© (GD ì˜µì…˜ì— ë”°ë¼)
    current_df = merge_asset_data(current_df, asset_minmax_df, group_df_prepared, gd_option)

    codes = current_df["CODE"].astype(str).tolist()
    try:
        validate_codes(price_df, codes)
    except ValueError as exc:
        st.error(str(exc))
        st.stop()

    reference_months = st.sidebar.number_input("ì°¸ì¡°ê¸°ê°„ (ê°œì›”)", min_value=12, max_value=120, value=36, step=3)
    turnover_limit = st.sidebar.number_input("íšŒì „ìœ¨ ì œì•½ (%)", min_value=0.0, max_value=200.0, value=100.0, step=5.0) / 100
    risk_free_rate = st.sidebar.number_input("ë¬´ìœ„í—˜ìˆ˜ìµë¥  (%)", value=0.0, step=0.1) / 100
    mar = st.sidebar.number_input("Sortino ìµœì†Œìˆ˜ìµë¥  (%)", value=0.0, step=0.25) / 100
    mc_sims = st.sidebar.number_input("ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜", min_value=100, max_value=5000, value=1000, step=100)
    expected_method = st.sidebar.radio(
        "ê¸°ëŒ€ìˆ˜ìµë¥  ì‚°ì¶œ ë°©ì‹",
        ("excel", "historical", "monte_carlo"),
        format_func=lambda x: {"excel": "ì—‘ì…€ ì…ë ¥", "historical": "ê³¼ê±°ìˆ˜ìµë¥ ", "monte_carlo": "ëª¬í…Œì¹¼ë¡œ"}[x],
    )

    # ì—‘ì…€ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•œ ê²½ìš° ëŒ€ì²´ ë°©ì‹ ì„ íƒ
    replacement_method = None
    if expected_method == "excel":
        replacement_method = st.sidebar.radio(
            "ê¸°ëŒ€ìˆ˜ìµë¥  ì—†ì„ ê²½ìš° ëŒ€ì²´ ë°©ë²•",
            ("historical", "monte_carlo"),
            index=0,  # default: ê³¼ê±°ìˆ˜ìµë¥ 
            format_func=lambda x: {"historical": "ê³¼ê±°ìˆ˜ìµë¥ ", "monte_carlo": "ëª¬í…Œì¹¼ë¡œ"}[x],
        )

    st.subheader("í˜„ì¬ ìì‚° ì •ë³´")
    # í‘œì‹œìš© ì»¬ëŸ¼ ì„ íƒ (CODE ì œì™¸)
    display_cols = ["NAME", "CURRENT", "MIN", "MAX"]
    if "DUR" in current_df.columns:
        display_cols.append("DUR")
    if "YLD" in current_df.columns:
        display_cols.append("YLD")
    if "EXPECTED_R" in current_df.columns:
        display_cols.append("EXPECTED_R")
    if "GROUP" in current_df.columns:
        display_cols.append("GROUP")
    if "Gr_Min" in current_df.columns:
        display_cols.append("Gr_Min")
    if "Gr_Max" in current_df.columns:
        display_cols.append("Gr_Max")
    
    current_df_display = current_df[display_cols].copy()
    current_df_display = format_display_df(current_df_display, raw_expected_r)
    
    # ìŠ¤íƒ€ì¼ë§: NAME(Sleeve)ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì¹¼ëŸ¼ì€ ì˜¤ë¥¸ìª½ ì •ë ¬ + 1ì¹¸ ë“¤ì—¬ì“°ê¸°
    def style_dataframe(df):
        styles = []
        for col in df.columns:
            if col != "Sleeve":
                styles.append({
                    'selector': f'th.col_{col}',
                    'props': [('text-align', 'right'), ('padding-right', '1em')]
                })
                styles.append({
                    'selector': f'td.col_{col}',
                    'props': [('text-align', 'right'), ('padding-right', '1em')]
                })
        return styles
    
    # Streamlit dataframeì— ìŠ¤íƒ€ì¼ ì ìš©
    st.markdown("""
    <style>
        /* ëª¨ë“  í…Œì´ë¸” ì…€ì— ëŒ€í•´ Sleeve ì¹¼ëŸ¼ì„ ì œì™¸í•˜ê³  ì˜¤ë¥¸ìª½ ì •ë ¬ */
        div[data-testid="stDataFrame"] table thead tr th:not(:first-child),
        div[data-testid="stDataFrame"] table tbody tr td:not(:first-child),
        div[data-testid="stDataFrame"] table th:not(:first-child),
        div[data-testid="stDataFrame"] table td:not(:first-child) {
            text-align: right !important;
            padding-right: 1em !important;
        }
        /* ë” êµ¬ì²´ì ì¸ ì„ íƒìë¡œ í™•ì‹¤í•˜ê²Œ ì ìš© */
        div[data-testid="stDataFrame"] table th[data-testid*="columnHeader"]:not(:first-child),
        div[data-testid="stDataFrame"] table td:not(:first-child) {
            text-align: right !important;
            padding-right: 1em !important;
        }
        /* ëª¨ë“  ê°€ëŠ¥í•œ í…Œì´ë¸” êµ¬ì¡°ì— ëŒ€í•´ ì ìš© */
        div[data-testid="stDataFrame"] table tr th:nth-child(n+2),
        div[data-testid="stDataFrame"] table tr td:nth-child(n+2) {
            text-align: right !important;
            padding-right: 1em !important;
        }
        /* í…Œì´ë¸” ìŠ¤í¬ë¡¤ ì œê±° - ëª¨ë“  í–‰ì´ í•œë²ˆì— ë³´ì´ë„ë¡ */
        div[data-testid="stDataFrame"] > div {
            max-height: none !important;
            overflow: visible !important;
        }
        div[data-testid="stDataFrame"] > div > div {
            max-height: none !important;
            overflow: visible !important;
        }
        div[data-testid="stDataFrame"] {
            max-height: none !important;
            overflow: visible !important;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.dataframe(current_df_display, use_container_width=True, hide_index=True)

    try:
        returns_df = compute_monthly_returns(price_df, codes, reference_months)
    except ValueError as exc:
        st.error(str(exc))
        st.stop()

    ann_returns = annualize_series(returns_df.mean())
    cov_monthly = returns_df.cov()
    cov_annual = cov_monthly * 12
    ann_vols = annualize_vol(np.sqrt(np.diag(cov_monthly)))
    ann_vols = pd.Series(ann_vols, index=returns_df.columns)

    # BM ìˆ˜ìµë¥  ë° DUR, YLD ê³„ì‚°
    bm_returns_monthly = None
    bm_dur = None
    bm_yld = None
    if has_bm:
        bm_returns_monthly = compute_bm_returns(bm_df, reference_months)
        if bm_returns_monthly is None:
            st.error("BM ì‹œíŠ¸ì—ì„œ TR ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # BM DUR, YLD ê³„ì‚° (ìµœì‹  ê°’ ì‚¬ìš©)
        bm_df_sorted = bm_df.copy()
        bm_df_sorted["DATE"] = pd.to_datetime(bm_df_sorted["DATE"], errors="coerce")
        bm_df_sorted = bm_df_sorted.sort_values("DATE")
        bm_dur = bm_df_sorted["DUR"].iloc[-1] if len(bm_df_sorted) > 0 and not pd.isna(
            bm_df_sorted["DUR"].iloc[-1]) else None
        bm_yld = bm_df_sorted["YLD"].iloc[-1] if len(bm_df_sorted) > 0 and not pd.isna(
            bm_df_sorted["YLD"].iloc[-1]) else None

        if bm_dur is None or bm_yld is None:
            st.error("BM ì‹œíŠ¸ì—ì„œ DUR ë˜ëŠ” YLD ê°’ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

    # ì—‘ì…€ì—ì„œ ê¸°ëŒ€ìˆ˜ìµë¥  ê°’ í™•ì¸
    # ì—‘ì…€ì—ì„œ % í˜•ì‹ìœ¼ë¡œ 500% ì…ë ¥ ì‹œ pandasê°€ 5.0ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì›ë³¸ ê°’ê³¼ ì •ê·œí™”ëœ ê°’ ëª¨ë‘ ì²´í¬
    excel_expected_r = current_df.set_index("CODE")["EXPECTED_R"] if "EXPECTED_R" in current_df.columns else pd.Series(dtype=float, index=current_df.set_index("CODE").index)
    
    # ì›ë³¸ ê°’ì—ì„œ 5.0 ë˜ëŠ” 500ì„ ì²´í¬, ë˜ëŠ” ì •ê·œí™”ëœ ê°’ì—ì„œ 5.0ì„ ì²´í¬
    # (ì—‘ì…€ì—ì„œ ì¼ë°˜ í˜•ì‹ìœ¼ë¡œ 500 ì…ë ¥ â†’ normalize_percentageì—ì„œ 500/100 = 5.0)
    # (ì—‘ì…€ì—ì„œ % í˜•ì‹ìœ¼ë¡œ 500% ì…ë ¥ â†’ pandasê°€ 5.0ìœ¼ë¡œ ì½ìŒ â†’ normalize_percentageì—ì„œ 5.0/100 = 0.05)
    raw_r_aligned = raw_expected_r.reindex(excel_expected_r.index) if len(raw_expected_r) > 0 else pd.Series(
        index=excel_expected_r.index)
    missing_r = excel_expected_r.isna() | np.isclose(excel_expected_r, 5.0, atol=0.1) | (raw_r_aligned.notna() & (
                np.isclose(raw_r_aligned, 5.0, atol=0.1) | np.isclose(raw_r_aligned, 500.0, atol=1.0)))

    # ëª¨ë“  ìì‚°ì´ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì—†ê³  ì—‘ì…€ì…ë ¥ì„ ì„ íƒí•œ ê²½ìš°
    if expected_method == "excel" and missing_r.all():
        st.error("ëª¨ë“  ìì‚°ì˜ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ì…ë ¥ ë°©ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±°ìˆ˜ìµë¥  ë˜ëŠ” ëª¬í…Œì¹¼ë¡œ ë°©ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()

    expected_returns = build_expected_returns(
        expected_method,
        current_df,
        ann_returns,
        returns_df.mean(),
        cov_monthly,
        mc_sims,
        raw_expected_r=raw_expected_r if len(raw_expected_r) > 0 else None,
        replacement_method=replacement_method,
    )
    expected_vols = build_expected_vols(
        expected_method,
        current_df,
        ann_vols,
        returns_df.mean(),
        cov_monthly,
        mc_sims,
        raw_expected_v=None,
        replacement_method=replacement_method,
    )

    # ë©”ì‹œì§€ ì²˜ë¦¬
    if expected_method == "excel" and missing_r.any():
        # ì¼ë¶€ ìì‚°ë§Œ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì—†ëŠ” ê²½ìš°
        missing_codes = current_df.loc[missing_r.values, "NAME"].tolist()
        missing_names = ", ".join(missing_codes)
        method_name = "ê³¼ê±°ìˆ˜ìµë¥ " if replacement_method == "historical" else "ëª¬í…Œì¹¼ë¡œ"
        st.warning(
            f"{missing_names} ìì‚°ì€ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ ë°©ì‹({method_name})ìœ¼ë¡œ ê°’ì„ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    elif expected_method in ["historical", "monte_carlo"] and missing_r.all():
        # ëª¨ë“  ìì‚°ì´ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì—†ê³  ê³¼ê±°ìˆ˜ìµë¥ /ëª¬í…Œì¹¼ë¡œë¥¼ ì„ íƒí•œ ê²½ìš°
        method_name = "ê³¼ê±°ìˆ˜ìµë¥ " if expected_method == "historical" else "ëª¬í…Œì¹¼ë¡œ"
        st.info(f"ëª¨ë“  ìì‚°ì˜ ê¸°ëŒ€ìˆ˜ìµë¥ ì´ ì—†ì–´ ì„ íƒí•œ ë°©ì‹({method_name})ìœ¼ë¡œ ê°’ì„ ëŒ€ì²´í•©ë‹ˆë‹¤.")

    # BM ì •ë³´ í‘œì‹œ
    st.subheader("ë²¤ì¹˜ë§ˆí¬ (BM) ì •ë³´")
    if not has_bm:
        st.info("âš ï¸ BM ì‚¬ìš© ì•ˆí•¨ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤. BMì´ ì—†ëŠ” ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    else:
        # BM ìˆ˜ìµë¥  ì •ë³´ í‘œì‹œ
        bm_ann_return = (1 + bm_returns_monthly.mean()) ** 12 - 1
        bm_ann_vol = np.std(bm_returns_monthly) * np.sqrt(12)
        bm_info = pd.DataFrame({
            "í•­ëª©": ["ì—°ìœ¨ ê¸°ëŒ€ìˆ˜ìµë¥ ", "ì—°ìœ¨ ë³€ë™ì„±", "DUR", "YLD", "ë°ì´í„° ê¸°ê°„"],
            "ê°’": [
                f"{bm_ann_return * 100:.2f}%",
                f"{bm_ann_vol * 100:.2f}%",
                f"{bm_dur:.2f}",
                f"{bm_yld * 100:.2f}%",
                f"{len(bm_returns_monthly)}ê°œì›”"
            ]
        })
        st.dataframe(bm_info, use_container_width=True, hide_index=True)

    current_weights = current_df["CURRENT"].fillna(0).values
    if current_weights.sum() == 0:
        st.error("Current ì‹œíŠ¸ì˜ CURRENT ì»¬ëŸ¼ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤.")
        st.stop()
    current_weights = current_weights / current_weights.sum()

    dur_array = current_df["DUR"].fillna(0).values
    yld_array = current_df["YLD"].fillna(0).values

    current_duration = np.dot(current_weights, dur_array)
    current_yield = np.dot(current_weights, yld_array)
    current_stats = portfolio_stats(
        current_weights,
        expected_returns.values,
        cov_annual.values,
        dur_array,
        yld_array,
        returns_df.values,
        mar,
        risk_free_rate,
    )

    st.sidebar.markdown("---")
    st.sidebar.markdown("### í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ì§€í‘œ")
    st.sidebar.markdown(f"**í˜„ì¬ ë“€ë ˆì´ì…˜:** {current_duration:.2f}")
    st.sidebar.markdown(f"**í˜„ì¬ YLD:** {current_yield * 100:.2f}%")
    if has_bm:
        st.sidebar.markdown(f"**BM ë“€ë ˆì´ì…˜:** {bm_dur:.2f}")
        st.sidebar.markdown(f"**BM YLD:** {bm_yld * 100:.2f}%")
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ì œì•½ì¡°ê±´ ì„¤ì •")

    if has_bm:
        # BM ëŒ€ë¹„ ì°¨ì´ ì œì•½ì¡°ê±´ë§Œ ì‚¬ìš©
        st.sidebar.markdown("#### BM ëŒ€ë¹„ ì°¨ì´ ì œì•½")
        dur_diff_min = st.sidebar.number_input("BM ëŒ€ë¹„ DUR ì°¨ì´ ìµœì†Œ", value=-1.0, step=0.1)
        dur_diff_max = st.sidebar.number_input("BM ëŒ€ë¹„ DUR ì°¨ì´ ìµœëŒ€", value=1.0, step=0.1)
        yld_diff_min = st.sidebar.number_input("BM ëŒ€ë¹„ YLD ì°¨ì´ ìµœì†Œ (%)", value=-0.5, step=0.1) / 100
        yld_diff_max = st.sidebar.number_input("BM ëŒ€ë¹„ YLD ì°¨ì´ ìµœëŒ€ (%)", value=0.5, step=0.1) / 100
        # BMì´ ìˆëŠ” ê²½ìš° ì ˆëŒ€ ì œì•½ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        dur_min = None
        dur_max = None
    else:
        dur_diff_min = None
        dur_diff_max = None
        yld_diff_min = None
        yld_diff_max = None
        dur_min_pct = st.sidebar.number_input("ë“€ë ˆì´ì…˜ ìµœì†Œ (%)", value=-20.0, step=1.0, help="í˜„ì¬ ë“€ë ˆì´ì…˜ ëŒ€ë¹„ í•˜í•œ ë¹„ìœ¨")
        dur_max_pct = st.sidebar.number_input("ë“€ë ˆì´ì…˜ ìµœëŒ€ (%)", value=20.0, step=1.0, help="í˜„ì¬ ë“€ë ˆì´ì…˜ ëŒ€ë¹„ ìƒí•œ ë¹„ìœ¨")
        dur_min = current_duration * (1 + dur_min_pct / 100)
        dur_max = current_duration * (1 + dur_max_pct / 100)
        st.sidebar.caption(f"ë“€ë ˆì´ì…˜ ë²”ìœ„: {dur_min:.2f} ~ {dur_max:.2f}")

    bounds = list(
        zip(
            current_df["MIN"].fillna(0).values,
            current_df["MAX"].fillna(1).values,
        )
    )

    # ë³‘í•©ëœ ë°ì´í„°ì—ì„œ GROUPë³„ Gr_Min, Gr_Maxë¥¼ ì‚¬ìš©í•˜ì—¬ group_limits ìƒì„±
    group_limits = {}
    if "GROUP" in current_df.columns and "Gr_Min" in current_df.columns and "Gr_Max" in current_df.columns:
        # ê° GROUPì˜ ì²« í–‰ì—ì„œ Gr_Min, Gr_Maxë¥¼ ê°€ì ¸ì˜´
        for group in current_df["GROUP"].unique():
            if pd.isna(group):
                continue
            group_rows = current_df[current_df["GROUP"] == group]
            if len(group_rows) > 0:
                gr_min = group_rows.iloc[0]["Gr_Min"]
                gr_max = group_rows.iloc[0]["Gr_Max"]
                # NaNì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                gr_min = gr_min if not pd.isna(gr_min) else 0
                gr_max = gr_max if not pd.isna(gr_max) else 1
                group_limits[group] = (gr_min, gr_max)
    else:
        # Gr_Min, Gr_Maxê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        for group in current_df["GROUP"].unique() if "GROUP" in current_df.columns else []:
            if pd.isna(group):
                continue
            group_limits[group] = (0, 1)
    group_map = {}
    for idx, row in current_df.reset_index().iterrows():
        group = row.get("GROUP")
        if pd.isna(group):
            continue
        group_map.setdefault(group, []).append(idx)

    objectives = [
        "Max Sharpe",
        "Max Sortino",
        "Max Return",
        "Min Risk",
        "Risk Parity",
        "Equal Weight",
    ]

    # BMì´ ìˆìœ¼ë©´ MaxIR ì¶”ê°€
    if has_bm:
        objectives.append("Max IR")

    # session_state ì´ˆê¸°í™”
    if "optimization_results" not in st.session_state:
        st.session_state.optimization_results = None
    if "optimization_objectives" not in st.session_state:
        st.session_state.optimization_objectives = None
    if "optimization_current_df" not in st.session_state:
        st.session_state.optimization_current_df = None
    if "optimization_current_weights" not in st.session_state:
        st.session_state.optimization_current_weights = None
    if "optimization_current_stats" not in st.session_state:
        st.session_state.optimization_current_stats = None

    if st.button("ìµœì í™” ì‹¤í–‰"):
        progress_placeholder = st.empty()
        progress_placeholder.info("ìµœì í™” ì§„í–‰ ì¤‘...")

        results = {}
        for obj in objectives:
            opt_w, stats, turnover = optimize_portfolio(
                obj,
                expected_returns.values,
                cov_annual.values,
                current_weights,
                bounds,
                group_map,
                group_limits,
                dur_array,
                yld_array,
                (dur_min, dur_max) if dur_min is not None else None,  # BMì´ ìˆëŠ” ê²½ìš° None
                None,  # YLD ì ˆëŒ€ê°’ ì œì•½ì¡°ê±´ ì‚¬ìš© ì•ˆí•¨
                turnover_limit,
                returns_df,
                mar,
                risk_free_rate,
                bm_returns_monthly=bm_returns_monthly,
                bm_dur=bm_dur if has_bm else None,
                bm_yld=bm_yld if has_bm else None,
                dur_diff_limits=(dur_diff_min, dur_diff_max) if has_bm else None,
                yld_diff_limits=(yld_diff_min, yld_diff_max) if has_bm else None,
            )

            # í¬íŠ¸í´ë¦¬ì˜¤ vs BM ë¹„êµ ì§€í‘œ ê³„ì‚°
            bm_stats = None
            if has_bm:
                bm_stats = portfolio_vs_bm_stats(opt_w, expected_returns.values, cov_annual.values, returns_df,
                                                 bm_returns_monthly)

            results[obj] = {
                "weights": opt_w,
                "stats": stats,
                "turnover": turnover,
                "bm_stats": bm_stats,
            }

        # ìµœì í™” ì™„ë£Œ í›„ ì§„í–‰ ë©”ì‹œì§€ ì œê±°
        progress_placeholder.empty()

        # ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
        st.session_state.optimization_results = results
        st.session_state.optimization_objectives = objectives
        st.session_state.optimization_current_df = current_df
        st.session_state.optimization_current_weights = current_weights
        st.session_state.optimization_current_stats = current_stats

    # ì €ì¥ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if st.session_state.optimization_results is not None:
        results = st.session_state.optimization_results
        objectives = st.session_state.optimization_objectives
        current_df = st.session_state.optimization_current_df
        current_weights = st.session_state.optimization_current_weights
        current_stats = st.session_state.optimization_current_stats

        # ì—‘ì…€ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜
        def create_excel_file():
            import io
            try:
                from openpyxl import Workbook
                from openpyxl.utils.dataframe import dataframe_to_rows
                
                excel_buffer = io.BytesIO()
                wb = Workbook()
                wb.remove(wb.active)  # ê¸°ë³¸ ì‹œíŠ¸ ì œê±°
                
                # ê¸°ë³¸ í…Œì´ë¸” êµ¬ì¡° (ëª¨ë“  ìì‚° í¬í•¨)
                base_table = current_df[["NAME"]].copy()
                
                # ê° ìµœì í™” ëª©í‘œë³„ë¡œ ì‹œíŠ¸ ìƒì„± (ëª¨ë“  í–‰ í¬í•¨)
                for obj in objectives:
                    opt = results[obj]["weights"]
                    table_export = base_table.copy()
                    table_export["Current Weight"] = [format_percentage(w) for w in current_weights]
                    table_export["Optimized Weight"] = [format_percentage(w) for w in opt]
                    table_export["Diff"] = [format_percentage(w) for w in (opt - current_weights)]
                    
                    # ì‹œíŠ¸ ì´ë¦„ ìƒì„± (ìµœëŒ€ 31ì)
                    sheet_name = obj[:31] if len(obj) > 31 else obj
                    ws = wb.create_sheet(title=sheet_name)
                    
                    # ë°ì´í„°í”„ë ˆì„ì„ ì‹œíŠ¸ì— ì¶”ê°€
                    for r in dataframe_to_rows(table_export, index=False, header=True):
                        ws.append(r)
                
                # ë°©ë²•ë¡ ë³„ optimized weightë§Œ ìˆëŠ” ì‹œíŠ¸ ìƒì„± (Current Weight í¬í•¨)
                summary_table = base_table.copy()
                summary_table["Current Weight"] = [format_percentage(w) for w in current_weights]
                for obj in objectives:
                    opt = results[obj]["weights"]
                    # ì‹œíŠ¸ ì´ë¦„ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš© (ìµœëŒ€ 31ì)
                    col_name = obj[:31] if len(obj) > 31 else obj
                    summary_table[col_name] = [format_percentage(w) for w in opt]
                
                ws_summary = wb.create_sheet(title="Summary", index=0)  # ì²« ë²ˆì§¸ ì‹œíŠ¸ë¡œ
                for r in dataframe_to_rows(summary_table, index=False, header=True):
                    ws_summary.append(r)
                
                wb.save(excel_buffer)
                excel_buffer.seek(0)
                return excel_buffer.getvalue()
            except ImportError:
                return None
        
        # ì—‘ì…€ íŒŒì¼ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
        excel_data = create_excel_file()
        if excel_data:
            st.download_button(
                label="ğŸ“¥ ìµœì í™” ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name="optimization_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("ì—‘ì…€ ë‚´ë³´ë‚´ê¸°ë¥¼ ìœ„í•´ openpyxl íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install openpyxlë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

        tabs = st.tabs(objectives)
        for tab, obj in zip(tabs, objectives):
            with tab:
                opt = results[obj]["weights"]
                stats = results[obj]["stats"]
                turnover = results[obj]["turnover"]

                table = current_df[["NAME"]].copy()
                table = table.rename(columns={"NAME": "Sleeve"})
                table["Current Weight"] = [format_percentage(w) for w in current_weights]
                table["Optimized Weight"] = [format_percentage(w) for w in opt]
                table["Diff"] = [format_percentage(w) for w in opt - current_weights]
                st.dataframe(table, use_container_width=True, hide_index=True)

                st.markdown(
                    f"""
                    - ê¸°ëŒ€ìˆ˜ìµë¥ : {format_percentage(stats['return'])}
                    - ë³€ë™ì„±: {format_percentage(stats['vol'])}
                    - ìƒ¤í”„ì§€ìˆ˜: {format_ratio(stats['sharpe'])}
                    - ì†Œë¥´í‹°ë…¸ì§€ìˆ˜: {format_ratio(stats['sortino'])}
                    - ë“€ë ˆì´ì…˜: {current_stats['duration']:.2f} -> {stats['duration']:.2f}
                    - YLD: {format_percentage(current_stats['yield'])} -> {format_percentage(stats['yield'])}
                    - íšŒì „ìœ¨: {format_percentage(turnover)}
                    """
                )

                # í¬íŠ¸í´ë¦¬ì˜¤ vs BM ë¹„êµ ì§€í‘œ í‘œì‹œ
                if has_bm and results[obj]["bm_stats"] is not None:
                    bm_stats = results[obj]["bm_stats"]
                    st.markdown("---")
                    st.markdown("### í¬íŠ¸í´ë¦¬ì˜¤ vs ë²¤ì¹˜ë§ˆí¬ ë¹„êµ")
                    st.markdown(
                        f"""
                        - í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ : {format_percentage(bm_stats['port_return'])}
                        - ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ : {format_percentage(bm_stats['bm_return'])}
                        - Alpha (ì´ˆê³¼ìˆ˜ìµë¥ ): {format_percentage(bm_stats['alpha'])}
                        - Tracking Error (TE): {format_percentage(bm_stats['tracking_error'])}
                        - Information Ratio (IR): {format_ratio(bm_stats['ir'])}
                        - ìƒê´€ê´€ê³„: {format_ratio(bm_stats['correlation'])}
                        - Beta: {format_ratio(bm_stats['beta'])}
                        """
                    )


if __name__ == "__main__":
    main()



